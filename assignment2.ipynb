{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afrahhassan/afrahhassan/blob/main/assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "# <div align=\"center\"><font>  </font></div>\n",
        "# <div align=\"center\"><font> COSC 2793 Computational Machine Learning </font></div>\n",
        "## <div align=\"center\"> <font> Assignment 2: Machine Learning Project </font></div>\n",
        "## <div align=\"center\"> <font> S3930076 Afrah Hassan A Alshaikh Ali & S3569266 Chang Su </font></div>\n",
        "---"
      ],
      "metadata": {
        "id": "1qSifWPkfTvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Libraries"
      ],
      "metadata": {
        "id": "twD8DWapfFnM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4OWaeUGKfFku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reading Data**"
      ],
      "metadata": {
        "id": "9PmzuCjISE7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr1U8kyVO1GI",
        "outputId": "d95a2cd2-3ad4-46ac-9ef4-c421ab619837"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rVvN_smBe9Jf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/ML/Assignment2\" . #Afrah"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjuFGZi-TWzC",
        "outputId": "70c242c4-72f1-4239-a8fe-5720102dd388"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/drive/MyDrive/ML/Assignment2': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/MyDrive/Assignment2\" . #Chang"
      ],
      "metadata": {
        "id": "F-52jr_lY2sU"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "# For Afrah\n",
        "# zip_file_path = '/content/drive/My Drive/ML/Assignment2/trafficsigns_dataset.zip'\n",
        "# For Chang\n",
        "zip_file_path = '/content/drive/My Drive/Assignment2/trafficsigns_dataset.zip'\n",
        "extract_to_path = '/content/trafficsigns_dataset'\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_path)\n",
        "print(\"Extraction completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPTRZMWnYJeA",
        "outputId": "c33ffc5d-f359-4cb4-be1f-630adadef24d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "root_dir = '/content/trafficsigns_dataset'\n",
        "# For Afrah\n",
        "output_csv = '/content/drive/My Drive/ML/Assignment2/images.csv'\n",
        "# For Susan\n",
        "output_csv = '/content/images.csv'\n",
        "\n",
        "with open(output_csv, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['image_path', 'class'])\n",
        "\n",
        "    for root, dirs, files in os.walk(root_dir):\n",
        "        for file in files:\n",
        "            if file.endswith(('.png', '.jpg', '.jpeg')):\n",
        "                full_path = os.path.join(root, file)\n",
        "                class_name = os.path.basename(root)\n",
        "                writer.writerow([full_path, class_name])\n",
        "print(\"CSV file has been created successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kf39c_iPYKZF",
        "outputId": "11da12cb-c5f7-4204-945c-5796e493b429"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file has been created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path for the output CSV file\n",
        "#Afrah\n",
        "output_csv = '/content/drive/My Drive/ML/Assignment2/image2.csv'  # Corrected the filename extension from '.cs' to '.csv'\n",
        "#Susan\n",
        "output_csv = '/content/image2.csv'  # Corrected the filename extension from '.cs' to '.csv'\n",
        "root_dir = '/content/trafficsigns_dataset'  # Directory containing subfolders of images\n",
        "\n",
        "# This list will hold all unique folder names which correspond to shape classes\n",
        "class_names = []\n",
        "\n",
        "# Opening a file to write into, make sure you have the correct permissions or the path exists\n",
        "with open(output_csv, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['image_path', 'shape'])  # Define the column headers for image paths and shape types\n",
        "\n",
        "    # Walk through the directory structure\n",
        "    for root, dirs, files in os.walk(root_dir):\n",
        "        for file in files:\n",
        "            # Check for image files ending with .png, .jpg, or .jpeg\n",
        "            if file.endswith(('.png', '.jpg', '.jpeg')):\n",
        "                full_path = os.path.join(root, file)  # Full path to the image\n",
        "                shape_name = os.path.basename(root)  # Folder name is taken as the shape name\n",
        "\n",
        "                # If this shape_name is not already in the list, add it\n",
        "                if shape_name not in class_names:\n",
        "                    class_names.append(shape_name)\n",
        "\n",
        "                # Write the path and shape_name to the CSV file\n",
        "                writer.writerow([full_path, shape_name])\n",
        "\n",
        "print(\"CSV file has been created successfully.\")\n",
        "print(\"Detected shape classes:\", class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRJsomEwk5be",
        "outputId": "7d77d647-52c1-4b27-90db-658d0c8427b2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file has been created successfully.\n",
            "Detected shape classes: ['warning', 'giveway', 'roundabout', 'limitedtraffic', 'noparking', 'traveldirection', 'trafficdirective', 'noentry', 'bicycle', 'speed', 'continue', 'laneend', 'parking', 'crossing', 'rightofway', 'stop']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FzmpDTrpk17Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def preprocess_images(data_path):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for shape_dir in os.listdir(data_path):\n",
        "        shape_dir_path = os.path.join(data_path, shape_dir)\n",
        "        if not os.path.isdir(shape_dir_path):\n",
        "            continue  # Skip non-directory files like .DS_Store\n",
        "        for type_dir in os.listdir(shape_dir_path):\n",
        "            type_dir_path = os.path.join(shape_dir_path, type_dir)\n",
        "            if not os.path.isdir(type_dir_path):\n",
        "                continue  # Skip non-directory files\n",
        "            for img_file in os.listdir(type_dir_path):\n",
        "                img_path = os.path.join(type_dir_path, img_file)\n",
        "                if not img_path.endswith(('.png', '.jpg', '.jpeg')): # Check if file is an image\n",
        "                    print(f\"Skipped non-image file: {img_path}\")\n",
        "                    continue\n",
        "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "                if img is None:\n",
        "                    print(f\"Failed to read image: {img_path}\")\n",
        "                    continue\n",
        "                if img.shape[0] == 0 or img.shape[1] == 0:\n",
        "                    print(f\"Empty image: {img_path}\")\n",
        "                    continue\n",
        "                img = cv2.resize(img, (28, 28))  # Resize to 28x28\n",
        "                img = img.astype('float32') / 255.0  # Normalize pixel values\n",
        "                images.append(img)\n",
        "                labels.append((shape_dir, type_dir))\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "    return images, labels\n",
        "\n"
      ],
      "metadata": {
        "id": "WOq3LOlEkKkz"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "def split_data(images, labels):\n",
        "    train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "        images, labels, test_size=0.2, random_state=42)\n",
        "    return train_images, test_images, train_labels, test_labels\n",
        "\n",
        "# Usage\n",
        "data_path = \"trafficsigns_dataset\"\n",
        "images, labels = preprocess_images(data_path)\n",
        "train_images, test_images, train_labels, test_labels = split_data(images, labels)"
      ],
      "metadata": {
        "id": "Z_PHIK8AuJb9",
        "outputId": "7ade855d-c3e5-4149-8223-767c7badbd42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing image: trafficsigns_dataset/trafficsigns_dataset/triangle/warning\n",
            "Processing image: trafficsigns_dataset/trafficsigns_dataset/triangle/giveway\n",
            "Processing image: trafficsigns_dataset/trafficsigns_dataset/round/roundabout\n",
            "Processing image: trafficsigns_dataset/trafficsigns_dataset/round/limitedtraffic\n",
            "Processing image: trafficsigns_dataset/trafficsigns_dataset/round/noparking\n",
            "Processing image: trafficsigns_dataset/trafficsigns_dataset/round/traveldirection\n",
            "Processing image: trafficsigns_dataset/trafficsigns_dataset/round/trafficdirective\n",
            "Processing image: trafficsigns_dataset/trafficsigns_dataset/round/noentry\n",
            "Processing image: trafficsigns_dataset/trafficsigns_dataset/round/bicycle\n",
            "Processing image: trafficsigns_dataset/trafficsigns_dataset/round/.DS_Store\n",
            "Processing image: trafficsigns_dataset/trafficsigns_dataset/round/speed\n",
            "Processing image: trafficsigns_dataset/trafficsigns_dataset/square/continue\n",
            "Processing image: trafficsigns_dataset/trafficsigns_dataset/square/laneend\n",
            "Processing image: trafficsigns_dataset/trafficsigns_dataset/square/parking\n",
            "Processing image: trafficsigns_dataset/trafficsigns_dataset/square/crossing\n",
            "Processing image: trafficsigns_dataset/trafficsigns_dataset/square/.DS_Store\n",
            "Processing image: trafficsigns_dataset/trafficsigns_dataset/diamond/rightofway\n",
            "Processing image: trafficsigns_dataset/trafficsigns_dataset/hex/stop\n",
            "Processing image: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/triangle\n",
            "Processing image: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/._hex\n",
            "Processing image: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/round\n",
            "Processing image: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/square\n",
            "Processing image: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/._triangle\n",
            "Processing image: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/._round\n",
            "Processing image: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/._square\n",
            "Processing image: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/diamond\n",
            "Processing image: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/._Readme.txt\n",
            "Processing image: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/hex\n",
            "Processing image: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/._diamond\n",
            "Processing image: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/._.DS_Store\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No images loaded. Dataset is empty.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-110fd8953b24>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"trafficsigns_dataset\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-d8eb5646d01d>\u001b[0m in \u001b[0;36mpreprocess_images\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# Add error handling for empty dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No images loaded. Dataset is empty.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No images loaded. Dataset is empty."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform EDA\n",
        "# Check number of samples and features\n",
        "print(\"Number of samples:\", len(images))\n",
        "print(\"Number of classes:\", len(np.unique(labels)))"
      ],
      "metadata": {
        "id": "KEACI28exUd1",
        "outputId": "a4c0fd1f-93c8-413f-f89f-b8c836b77d74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 0\n",
            "Number of classes: 0\n"
          ]
        }
      ]
    }
  ]
}