{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afrahhassan/afrahhassan/blob/main/assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "# <div align=\"center\"><font>  </font></div>\n",
        "# <div align=\"center\"><font> COSC 2793 Computational Machine Learning </font></div>\n",
        "## <div align=\"center\"> <font> Assignment 2: Machine Learning Project </font></div>\n",
        "## <div align=\"center\"> <font> S3930076 Afrah Hassan A Alshaikh Ali & S3569266 Chang Su </font></div>\n",
        "---"
      ],
      "metadata": {
        "id": "1qSifWPkfTvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Libraries"
      ],
      "metadata": {
        "id": "twD8DWapfFnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reading Data**"
      ],
      "metadata": {
        "id": "9PmzuCjISE7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr1U8kyVO1GI",
        "outputId": "fa6881a3-d9eb-4f53-9407-1345dec81def"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir('/content/drive/MyDrive/Assignment2')\n"
      ],
      "metadata": {
        "id": "ash2JewSo2lQ",
        "outputId": "7f723469-ce44-402e-cc6b-b68978687572",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['assignment2_PG.pdf',\n",
              " 'COSC2673_2793_A2_EOI_.docx',\n",
              " 'trafficsigns_dataset',\n",
              " 'images.gsheet',\n",
              " 'image2.csv',\n",
              " 'trafficsigns_dataset.zip',\n",
              " 'images.csv',\n",
              " 'assignment2.ipynb']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rVvN_smBe9Jf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/ML/Assignment2\" . #Afrah"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjuFGZi-TWzC",
        "outputId": "002832a9-f1c9-4c22-dee9-55287a564f98"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/drive/MyDrive/ML/Assignment2': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/MyDrive/Assignment2\" . #Chang"
      ],
      "metadata": {
        "id": "F-52jr_lY2sU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "# For Afrah\n",
        "# zip_file_path = '/content/drive/My Drive/ML/Assignment2/trafficsigns_dataset.zip'\n",
        "# For Chang\n",
        "zip_file_path = '/content/drive/My Drive/Assignment2/trafficsigns_dataset.zip'\n",
        "extract_to_path = '/content/trafficsigns_dataset'\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_path)\n",
        "print(\"Extraction completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPTRZMWnYJeA",
        "outputId": "f9f3a524-9f3d-40d0-cf28-a7842a798e51"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "root_dir = '/content/trafficsigns_dataset'\n",
        "# For Afrah\n",
        "output_csv = '/content/drive/My Drive/Assignment2/images.csv'\n",
        "# For Susan\n",
        "output_csv = '/content/images.csv'\n",
        "\n",
        "with open(output_csv, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['image_path', 'class'])\n",
        "\n",
        "    for root, dirs, files in os.walk(root_dir):\n",
        "        for file in files:\n",
        "            if file.endswith(('.png', '.jpg', '.jpeg')):\n",
        "                full_path = os.path.join(root, file)\n",
        "                class_name = os.path.basename(root)\n",
        "                writer.writerow([full_path, class_name])\n",
        "print(\"CSV file has been created successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kf39c_iPYKZF",
        "outputId": "5f108911-ac92-4ac1-eb52-e59a4c36fe2a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file has been created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path for the output CSV file\n",
        "#Afrah\n",
        "output_csv = '/content/drive/My Drive/ML/Assignment2/image2.csv'  # Corrected the filename extension from '.cs' to '.csv'\n",
        "#Susan\n",
        "output_csv = '/content/image2.csv'  # Corrected the filename extension from '.cs' to '.csv'\n",
        "root_dir = '/content/trafficsigns_dataset'  # Directory containing subfolders of images\n",
        "\n",
        "# This list will hold all unique folder names which correspond to shape classes\n",
        "class_names = []\n",
        "\n",
        "# Opening a file to write into, make sure you have the correct permissions or the path exists\n",
        "with open(output_csv, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['image_path', 'shape'])  # Define the column headers for image paths and shape types\n",
        "\n",
        "    # Walk through the directory structure\n",
        "    for root, dirs, files in os.walk(root_dir):\n",
        "        for file in files:\n",
        "            # Check for image files ending with .png, .jpg, or .jpeg\n",
        "            if file.endswith(('.png', '.jpg', '.jpeg')):\n",
        "                full_path = os.path.join(root, file)  # Full path to the image\n",
        "                shape_name = os.path.basename(root)  # Folder name is taken as the shape name\n",
        "\n",
        "                # If this shape_name is not already in the list, add it\n",
        "                if shape_name not in class_names:\n",
        "                    class_names.append(shape_name)\n",
        "\n",
        "                # Write the path and shape_name to the CSV file\n",
        "                writer.writerow([full_path, shape_name])\n",
        "\n",
        "print(\"CSV file has been created successfully.\")\n",
        "print(\"Detected shape classes:\", class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRJsomEwk5be",
        "outputId": "996540a1-55bd-4a16-8991-84de5e3b4bce"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file has been created successfully.\n",
            "Detected shape classes: ['continue', 'laneend', 'parking', 'crossing', 'giveway', 'warning', 'rightofway', 'stop', 'speed', 'traveldirection', 'noparking', 'noentry', 'trafficdirective', 'roundabout', 'bicycle', 'limitedtraffic']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FzmpDTrpk17Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def preprocess_images(data_path):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for shape_dir in os.listdir(data_path):\n",
        "        shape_dir_path = os.path.join(data_path, shape_dir)\n",
        "        if not os.path.isdir(shape_dir_path):\n",
        "            continue  # Skip non-directory files like .DS_Store\n",
        "        for type_dir in os.listdir(shape_dir_path):\n",
        "            type_dir_path = os.path.join(shape_dir_path, type_dir)\n",
        "            if not os.path.isdir(type_dir_path):\n",
        "                continue  # Skip non-directory files\n",
        "            for img_file in os.listdir(type_dir_path):\n",
        "                img_path = os.path.join(type_dir_path, img_file)\n",
        "                if not img_path.endswith(('.png', '.jpg', '.jpeg')): # Check if file is an image\n",
        "                    print(f\"Skipped non-image file: {img_path}\")\n",
        "                    continue\n",
        "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "                if img is None:\n",
        "                    print(f\"Failed to read image: {img_path}\")\n",
        "                    continue\n",
        "                if img.shape[0] == 0 or img.shape[1] == 0:\n",
        "                    print(f\"Empty image: {img_path}\")\n",
        "                    continue\n",
        "                img = cv2.resize(img, (28, 28))  # Resize to 28x28\n",
        "                img = img.astype('float32') / 255.0  # Normalize pixel values\n",
        "                images.append(img)\n",
        "                labels.append((shape_dir, type_dir))\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "    return images, labels\n",
        "\n"
      ],
      "metadata": {
        "id": "WOq3LOlEkKkz"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "def split_data(images, labels):\n",
        "    train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "        images, labels, test_size=0.2, random_state=42)\n",
        "    return train_images, test_images, train_labels, test_labels\n",
        "\n",
        "# Usage\n",
        "data_path = \"trafficsigns_dataset\"\n",
        "images, labels = preprocess_images(data_path)\n",
        "train_images, test_images, train_labels, test_labels = split_data(images, labels)"
      ],
      "metadata": {
        "id": "Z_PHIK8AuJb9",
        "outputId": "4de6b629-d0fe-4fdb-9c75-55682b22bd13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 900
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipped non-image file: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/._square\n",
            "Skipped non-image file: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/._diamond\n",
            "Skipped non-image file: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/._hex\n",
            "Skipped non-image file: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/square\n",
            "Skipped non-image file: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/triangle\n",
            "Skipped non-image file: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/._.DS_Store\n",
            "Skipped non-image file: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/diamond\n",
            "Skipped non-image file: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/._triangle\n",
            "Skipped non-image file: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/hex\n",
            "Skipped non-image file: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/._round\n",
            "Skipped non-image file: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/round\n",
            "Skipped non-image file: trafficsigns_dataset/__MACOSX/trafficsigns_dataset/._Readme.txt\n",
            "Skipped non-image file: trafficsigns_dataset/trafficsigns_dataset/square/continue\n",
            "Skipped non-image file: trafficsigns_dataset/trafficsigns_dataset/square/laneend\n",
            "Skipped non-image file: trafficsigns_dataset/trafficsigns_dataset/square/parking\n",
            "Skipped non-image file: trafficsigns_dataset/trafficsigns_dataset/square/.DS_Store\n",
            "Skipped non-image file: trafficsigns_dataset/trafficsigns_dataset/square/crossing\n",
            "Skipped non-image file: trafficsigns_dataset/trafficsigns_dataset/triangle/giveway\n",
            "Skipped non-image file: trafficsigns_dataset/trafficsigns_dataset/triangle/warning\n",
            "Skipped non-image file: trafficsigns_dataset/trafficsigns_dataset/diamond/rightofway\n",
            "Skipped non-image file: trafficsigns_dataset/trafficsigns_dataset/hex/stop\n",
            "Skipped non-image file: trafficsigns_dataset/trafficsigns_dataset/round/speed\n",
            "Skipped non-image file: trafficsigns_dataset/trafficsigns_dataset/round/traveldirection\n",
            "Skipped non-image file: trafficsigns_dataset/trafficsigns_dataset/round/noparking\n",
            "Skipped non-image file: trafficsigns_dataset/trafficsigns_dataset/round/noentry\n",
            "Skipped non-image file: trafficsigns_dataset/trafficsigns_dataset/round/trafficdirective\n",
            "Skipped non-image file: trafficsigns_dataset/trafficsigns_dataset/round/.DS_Store\n",
            "Skipped non-image file: trafficsigns_dataset/trafficsigns_dataset/round/roundabout\n",
            "Skipped non-image file: trafficsigns_dataset/trafficsigns_dataset/round/bicycle\n",
            "Skipped non-image file: trafficsigns_dataset/trafficsigns_dataset/round/limitedtraffic\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-110fd8953b24>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"trafficsigns_dataset\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-110fd8953b24>\u001b[0m in \u001b[0;36msplit_data\u001b[0;34m(images, labels)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Split data into train and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     train_images, test_images, train_labels, test_labels = train_test_split(\n\u001b[0m\u001b[1;32m      4\u001b[0m         images, labels, test_size=0.2, random_state=42)\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2563\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2236\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2237\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2238\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform EDA\n",
        "# Check number of samples and features\n",
        "print(\"Number of samples:\", len(images))\n",
        "print(\"Number of classes:\", len(np.unique(labels)))"
      ],
      "metadata": {
        "id": "KEACI28exUd1",
        "outputId": "a4c0fd1f-93c8-413f-f89f-b8c836b77d74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 0\n",
            "Number of classes: 0\n"
          ]
        }
      ]
    }
  ]
}